{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from support.charting import primaryColors, fullColors, save_fig\n",
    "from support.load     import loadAllData, methodParams\n",
    "from support.util     import titles, order, robustOutcomeOrder\n",
    "\n",
    "from IPython.core import display as ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadAllData()\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dataframes to summarize robust data. This is used for most of the charts in this notebook. \n",
    "robustData = []\n",
    "for method in data.keys(): \n",
    "    for model in order('model'):\n",
    "        for idx, rbData in enumerate(data[method]['robusts'][model]):\n",
    "            ref = idx\n",
    "            if len(rbData) == 1 or idx == len(rbData) - 1: \n",
    "                ref = -1\n",
    "            rb = rbData[order('outcome')]\n",
    "            rb['policy'] = rbData['policy']\n",
    "            rb['model'], rb['method'], rb['reference_scenario'] = [model, method, ref]\n",
    "            robustData.append(rb)\n",
    "\n",
    "robustData = pd.concat(robustData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = robustData[robustData['model']=='plannedadaptive']\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Dimensional Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(g):\n",
    "    ci95_hi = g.mean() + g.sem() * 1.96\n",
    "    ci95_lo = g.mean() - g.sem() * 1.96\n",
    "    mean = g.mean()\n",
    "    \n",
    "    return g.mean(), g.median(), ci95_lo, ci95_hi, g.min(), g.max(), g.quantile(0.10), g.quantile(0.90)\n",
    "\n",
    "def make_pivot_table(data, rows=None, columns=None, values=None):\n",
    "    stacked = pd.pivot_table(data, values=values, index=rows,\n",
    "                             columns=columns, dropna=False)\n",
    "    stacked.index.names = rows\n",
    "    stacked.columns.names = columns\n",
    "\n",
    "    return stacked\n",
    "\n",
    "def buildStackedHeatmapResults(robustSummary, columns='method', rows='outcome', rowGroups='model', mapped='mean'): \n",
    "    outerRowOrder = ['plannedadaptive']\n",
    "    innerRowOrder = order(columns)\n",
    "    outerColumnOrder = order(rows)\n",
    "    innerColumnOrder = ['mean', 'median','ci_low','ci_high','min','max','quartile_low','quartile_high']\n",
    "    \n",
    "    col = pd.MultiIndex(levels=[outerColumnOrder, \n",
    "                            innerColumnOrder],\n",
    "                        labels=[np.repeat(list(range(len(outerColumnOrder))),len(innerColumnOrder)), \n",
    "                                np.tile(list(range(len(innerColumnOrder))),len(outerColumnOrder))],\n",
    "                        names=[rows,'stat'])\n",
    "    idx = pd.MultiIndex(levels=[outerRowOrder, innerRowOrder],\n",
    "                        labels=[np.repeat(list(range(len(outerRowOrder))),len(innerRowOrder)), \n",
    "                                np.tile(list(range(len(innerRowOrder))),len(outerRowOrder))],\n",
    "                        names=[rowGroups, columns])\n",
    "    results = pd.DataFrame(np.zeros((idx.shape[0], col.shape[0])), columns=col, index=idx)\n",
    "\n",
    "    group = robustSummary.groupby([rowGroups, columns])\n",
    "    ci = group.apply(stats)\n",
    "\n",
    "    for outcome in order(rows): \n",
    "        for outer in outerRowOrder: \n",
    "            for inner in innerRowOrder:\n",
    "                for idx, stat in enumerate(innerColumnOrder): \n",
    "                    results.loc[(outer,inner),(outcome,stat)] = ci[outer][inner][idx][outcome]\n",
    "    \n",
    "    statDf = results.xs(mapped, level=1, axis=1)\n",
    "    statDf = pd.DataFrame(statDf.to_records())\n",
    "\n",
    "    dfs = []\n",
    "    for outcome in order(rows): \n",
    "        df = statDf[[rowGroups,columns,outcome]]\n",
    "        df.columns = [rowGroups,columns,'value']\n",
    "        df[rows] = outcome\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs) \n",
    "    \n",
    "    pivot = make_pivot_table(df, rows=[rowGroups, rows], columns=[columns], values='value')\n",
    "\n",
    "    indexOrder = []\n",
    "    for level1 in order(rowGroups):\n",
    "        for level2 in order(rows):\n",
    "            indexOrder.append((level1,level2))\n",
    "    pivot = pivot.reindex(indexOrder)\n",
    "\n",
    "    # Rename Rows\n",
    "    outerRowOrder = pivot.index.levels[0]\n",
    "    rowOrder = pivot.index.levels[1]\n",
    "    pivot.index = pivot.index.set_levels([titles(rowGroups, outerRowOrder), titles(rows, rowOrder)], level=[0,1])\n",
    "    # Rename columns\n",
    "    pivot = pivot.reindex_axis(order(columns), axis=1)\n",
    "    pivot.columns = titles(columns)\n",
    "    \n",
    "    # Rename stats table to match updated pivot table\n",
    "    results.index = results.index.set_levels([['Planned Adaptive DPS\\n(t=10)'], titles('method')])\n",
    "    results.columns = results.columns.set_levels([titles('outcome'),list(results.columns.levels[1])])\n",
    "    \n",
    "    return pivot, results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCumulativeHeatmap(pivot, labels=True, mapped='mean'): \n",
    "    if isinstance(labels, str): \n",
    "        plt.rc('text', usetex=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(7.5,3))\n",
    "    gs = mpl.gridspec.GridSpec(1, 2, width_ratios=[1,3.2],wspace=0.01) \n",
    "    ax0 = plt.subplot(gs[0])\n",
    "\n",
    "    ax_plot = fig.add_subplot(gs[1])\n",
    "\n",
    "    hmap = sns.heatmap(pivot.values, ax=ax_plot, cmap='plasma', annot=False, fmt='', \n",
    "                       annot_kws={'size':9}, vmin=0, vmax=1)\n",
    "    hmap.axes.xaxis.tick_top()\n",
    "    hmap.axes.set_ylabel('')\n",
    "\n",
    "    # Configure Axis Tick Labels\n",
    "    hmap.axes.set_xticklabels(titles('method'), fontsize=10)\n",
    "    ax_plot.set_yticks([])\n",
    "    \n",
    "#     put labels manually\n",
    "    for y in range(labels.shape[0]):\n",
    "        for x in range(labels.shape[1]):\n",
    "            color = 'black' if pivot.iloc[y, x] > 0.8 else 'white'\n",
    "            plt.text(x+0.5, y+0.3,labels[y, x][0], ha='center',va='center',color=color, \n",
    "                     family='sans-serif', size=10, weight='bold')\n",
    "            plt.text(x+0.5, y+0.6,labels[y, x][1], ha='center',va='center',color=color, \n",
    "                     family='sans-serif', size=10)\n",
    "#             plt.text(x+0.5, y+0.5,labels[y, x][0], ha='center',va='center',color=color, \n",
    "#                      family='sans-serif', size=16, weight='bold')\n",
    "\n",
    "\n",
    "    # Configure line breaks\n",
    "    linewidth = 10\n",
    "    color = 'w'\n",
    "    for i in range(1,12): \n",
    "        hmap.axhline(y=i, linewidth=1, color=color)\n",
    "    hmap.axhline(y=4, linewidth=linewidth, color=color)\n",
    "    hmap.axhline(y=8, linewidth=linewidth, color=color)\n",
    "    hmap.axvline(x=1, linewidth=linewidth, color=color)\n",
    "    hmap.axvline(x=2, linewidth=linewidth, color=color)\n",
    "    \n",
    "    #-- Dimension Titles --\n",
    "\n",
    "    #Display Formatting\n",
    "    ax_dim = fig.add_subplot(gs[0])\n",
    "    ax_dim.set_ylim(ax_plot.get_ylim())\n",
    "    ax_dim.set_xlim(0, 1)\n",
    "    ax_dim.set_yticks([])\n",
    "    ax_dim.set_xticks([])\n",
    "\n",
    "    ax_dim.spines['left'].set_color('white')\n",
    "    ax_dim.spines['left'].set_linewidth(1.0)\n",
    "    ax_dim.spines['right'].set_color('white')\n",
    "    ax_dim.spines['right'].set_linewidth(1.0)\n",
    "    ax_dim.spines['top'].set_color('black')\n",
    "    ax_dim.spines['top'].set_linewidth(1.0)\n",
    "    ax_dim.spines['bottom'].set_color('black')\n",
    "    ax_dim.spines['bottom'].set_linewidth(1.0)\n",
    "\n",
    "    #Configure Name Text\n",
    "    index = pivot.index[::-1]\n",
    "    nr_levels = len(index.levels)\n",
    "    levels = index.levels\n",
    "    indices = index.values[::-1]\n",
    "\n",
    "    #Add horizontal lines to grid\n",
    "    ct = 1\n",
    "    for i in range(len(index.levels[0])):\n",
    "        place = [ct,ct+1,ct+2,ct+3]\n",
    "        ax_dim.plot([0.5, 1], [place[0],place[0]], lw=1, color='gray')\n",
    "        ax_dim.plot([0.5, 1], [place[1],place[1]], lw=1, color='gray')\n",
    "        ax_dim.plot([0.5, 1], [place[2],place[2]], lw=1, color='gray')\n",
    "\n",
    "        ax_dim.plot([0, 1], [place[3],place[3]], lw=1, color='black')\n",
    "        ct += 4\n",
    "\n",
    "    #Add both levels of text to grid\n",
    "    currDim = ''\n",
    "    offset = 0\n",
    "    for idx, ind in enumerate(index.values[::-1]): \n",
    "        if ind[0] != currDim: \n",
    "            currDim = ind[0]\n",
    "            print(currDim)\n",
    "            print(nr_levels)\n",
    "            print(index.levels[1])\n",
    "            ax_dim.text(1/(2*nr_levels) + 0/(nr_levels), len(index.levels[1])/2+idx, ind[0], ha='center', va='center',weight='bold', fontsize=10, rotation='vertical')\n",
    "\n",
    "        ax_dim.text(1/(2*nr_levels) + 1/(nr_levels), 0.041667*12+idx, ind[1], ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    plt.suptitle(mapped.capitalize() + ' Robustness per Outcome, Random Reference Scenarios',y=1.05,weight='bold',fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_fig(fig, 'images/hmaps/', 'robustnes_random')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return hmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot, statFrame = buildStackedHeatmapResults(dat)\n",
    "pivot = pivot.drop('Intertemporal',level=0)\n",
    "pivot = pivot.drop('Direct Policy Search\\n(t=1)',level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for dim, row in pivot.index: \n",
    "    labelset = []\n",
    "    for col in pivot.columns:\n",
    "        l = statFrame.loc[(dim, col),(row,'ci_low')]\n",
    "        h = statFrame.loc[(dim, col),(row,'ci_high')]\n",
    "        m = statFrame.loc[(dim, col),(row,'mean')]\n",
    "        \n",
    "#         label = r'$\\bf{' + '{0:.2f}'.format(m) + \"}$\" + '\\n(' + '{0:.2f}'.format(l) + ', ' + '{0:.2f}'.format(h) + ')'\n",
    "        label = ('{0:.2f}'.format(m),'(' + '{0:.2f}'.format(l) + ', ' + '{0:.2f}'.format(h) + ')')\n",
    "        labelset.append(label)\n",
    "    labels.append(labelset)\n",
    "\n",
    "fig = buildCumulativeHeatmap(pivot, labels=np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
