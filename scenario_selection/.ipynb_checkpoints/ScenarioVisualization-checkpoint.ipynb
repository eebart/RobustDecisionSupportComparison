{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../charting')\n",
    "sys.path.append('../run_analysis')\n",
    "\n",
    "from support.util import modelTitle\n",
    "from support.charting import primaryColors, fullColors, save_fig\n",
    "from modelConfig import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core import display as ICD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker  \n",
    "import numpy.lib.recfunctions as rf\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from ema_workbench import (perform_experiments, ema_logging, save_results, \n",
    "                           load_results)\n",
    "from ema_workbench.em_framework import samplers\n",
    "from ema_workbench.em_framework import sample_levers\n",
    "\n",
    "# turn on logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup and Plotting Methods\n",
    "\n",
    "fs = 12\n",
    "\n",
    "def setup_parallel_plot(labels, maxima, minima, new_labels, rot=0):\n",
    "    #labels is a list, minima and maxima pd series\n",
    "    nr_columns = len(labels)\n",
    "    fig = plt.figure()\n",
    "    axes = []\n",
    "    \n",
    "    # we need one axes less than the shape\n",
    "    for i, label in enumerate(labels[:-1]):\n",
    "        i += 1\n",
    "        ax = fig.add_subplot(1,nr_columns-1,i,  ylim=(-0.1,1.1))\n",
    "        axes.append(ax)\n",
    "        ax.set_xlim([i,i+1])\n",
    "        ax.xaxis.set_major_locator(ticker.FixedLocator([i]))\n",
    "        if new_labels:\n",
    "            ax.xaxis.set_ticklabels([new_labels[i-1]]) #, rotation=90)\n",
    "        else:\n",
    "            ax.xaxis.set_ticklabels([labels[i-1]], rotation=rot)\n",
    "            \n",
    "\n",
    "        ax.xaxis.set_tick_params(bottom=False, top=False)\n",
    "        \n",
    "        #let's put our own tick labels\n",
    "        ax.yaxis.set_ticks([])\n",
    "        ax.text(i, ax.get_ylim()[1]+0.01, \"{:.2f}\".format(maxima[label]), ha=\"center\", fontsize=fs)\n",
    "        ax.text(i, ax.get_ylim()[0]-0.01,\"{:.2f}\".format(minima[label]), ha=\"center\", fontsize=fs)\n",
    "        \n",
    "        ax.spines['left'].set_bounds(0, 1)\n",
    "        ax.spines['right'].set_bounds(0, 1)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    \n",
    "    # for the last axis, we need 2 ticks (also for the right hand side\n",
    "    ax.spines['right'].set_bounds(0, 1)\n",
    "    ax.xaxis.set_major_locator(ticker.FixedLocator([i, i+1]))\n",
    "    if new_labels:\n",
    "        ax.xaxis.set_ticklabels(new_labels[i-1:i+1], fontsize=fs)\n",
    "    else:\n",
    "        ax.xaxis.set_ticklabels(labels[i-1:i+1], fontsize=fs)\n",
    "    ax.text(i+1, ax.get_ylim()[1]+0.01, \"{:.2f}\".format(maxima[labels[-1]]), ha=\"center\", fontsize=fs)\n",
    "    ax.text(i+1, ax.get_ylim()[0]-0.01,\"{:.2f}\".format(minima[labels[-1]]), ha=\"center\", fontsize=fs)\n",
    "    \n",
    "    # add the tick labels to the rightmost spine\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label2On=True\n",
    "    \n",
    "    # stack the subplots together\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    \n",
    "    return axes\n",
    "\n",
    "def normalize(data, minima, maxima):\n",
    "    #takes pandas dataframe as data, and series as minima and maxima\n",
    "    d = maxima - minima\n",
    "    d[d==0] = 1\n",
    "    norm_data = data.copy()\n",
    "    for col in data.columns:\n",
    "        norm_data[col] = (data[col]-minima[col])/d[col]\n",
    "    #norm_data = data/d - minima/d\n",
    "    return norm_data\n",
    "\n",
    "def change_fontsize(fig, fs=14):\n",
    "    '''Change fontsize of figure items to specified size'''\n",
    "    # TODO:: add legend and general text items\n",
    "\n",
    "    for ax in fig.axes:\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                      ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            item.set_fontsize(fs)\n",
    "        \n",
    "        try:\n",
    "            parasites = ax.parasites\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            for parisite in parasites:\n",
    "                for axis in parisite.axis.values():\n",
    "                    axis.major_ticklabels.set_fontsize(fs)\n",
    "                    axis.label.set_fontsize(fs)\n",
    "\n",
    "            for axis in ax.axis.values():\n",
    "                axis.major_ticklabels.set_fontsize(fs)\n",
    "                axis.label.set_fontsize(fs)\n",
    "        \n",
    "        if ax.legend_ != None:\n",
    "            for entry in ax.legend_.get_texts():\n",
    "                entry.set_fontsize(fs)\n",
    "                \n",
    "class Character(object):\n",
    "    '''\n",
    "    returns a character in the order of the alphabet    \n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counter = -1\n",
    "        \n",
    "    def __call__(self, kwargs):\n",
    "        self.counter += 1\n",
    "        if self.counter == 26: \n",
    "            self.counter = 0\n",
    "        return chr(ord('a') + self.counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform experiments\n",
    "nr_experiments = 500\n",
    "nr_policies = 10\n",
    "num_scenarios = 4\n",
    "folder = '../data/multi/scenarioselection/scens_pol' + str(nr_policies) + '/'\n",
    "\n",
    "results = {}\n",
    "for modelName, model in models.items(): \n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    fn = '{}{}_{}experiments_{}policies.tar.gz'.format(folder, modelName, nr_experiments, nr_policies)\n",
    "    policies = sample_levers(model,  n_samples=nr_policies, name=Character())\n",
    "\n",
    "    results[modelName] = load_results(fn)\n",
    "        \n",
    "randomSelected = []\n",
    "for x in range(num_scenarios):\n",
    "    randomSelected.append((random.randint(0,nr_experiments * nr_policies-1)))\n",
    "\n",
    "randomSelected.sort()\n",
    "randomSelected\n",
    "\n",
    "# 10 policies\n",
    "maxDiverse = {\n",
    "    'dps':[ 5, 61, 237, 312],\n",
    "    'plannedadaptive':[ 0, 8, 28, 30],\n",
    "    'intertemporal':[ 249, 344, 434, 492]\n",
    "}\n",
    "\n",
    "randomSelected = []\n",
    "for x in range(num_scenarios):\n",
    "    randomSelected.append((random.randint(0,nr_experiments * nr_policies-1)))\n",
    "\n",
    "randomSelected.sort()\n",
    "randomSelected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build logical index\n",
    "\n",
    "Run one of the three depending on how you want to select reference scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newResults = {}\n",
    "logicalIndex = {}\n",
    "\n",
    "for key, model in models.items(): \n",
    "    experiments, outcomes = results[key]\n",
    "    #here, the policy-relevant scenarios defined by median thresholds are selected\n",
    "    indices = []\n",
    "    for outcome in model.outcomes:\n",
    "        if outcome.kind == -1:\n",
    "            a = outcomes[outcome.name] > np.mean(outcomes[outcome.name])     \n",
    "        else: \n",
    "            a = outcomes[outcome.name] < np.mean(outcomes[outcome.name])\n",
    "        indices.append(a)\n",
    "    indices = np.swapaxes(indices, 0, 1)\n",
    "    logical_index = np.array([index.all() for index in indices])\n",
    "    logicalIndex[key] = logical_index\n",
    "\n",
    "    new_fn = '{}{}_meanselected_{}experiments_{}policies.tar.gz'.format(folder, key, nr_experiments, nr_policies)\n",
    "    try:\n",
    "        # why regenerate the data?\n",
    "        newResults[key] = load_results(new_fn)\n",
    "        print(key, newResults[key][0].shape)\n",
    "\n",
    "    except IOError:\n",
    "        newExperiments = experiments[logical_index]\n",
    "        newOutcomes = {}\n",
    "        for outcome in model.outcomes:\n",
    "            newOutcomes[outcome.name] = outcomes[outcome.name][logical_index]\n",
    "\n",
    "        newResults[key] = newExperiments, newOutcomes\n",
    "        print(newResults[key][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newResults = {}\n",
    "logicalIndex = {}\n",
    "\n",
    "for key, model in models.items(): \n",
    "    experiments, outcomes = results[key]\n",
    "    #here, the policy-relevant scenarios defined by median thresholds are selected\n",
    "    indices = []\n",
    "    for outcome in model.outcomes:\n",
    "        if outcome.kind == -1:\n",
    "            a = outcomes[outcome.name] > np.median(outcomes[outcome.name])     \n",
    "        else: \n",
    "            a = outcomes[outcome.name] < np.median(outcomes[outcome.name])\n",
    "        indices.append(a)\n",
    "    indices = np.swapaxes(indices, 0, 1)\n",
    "    logical_index = np.array([index.all() for index in indices])\n",
    "    logicalIndex[key] = logical_index\n",
    "\n",
    "    new_fn = '{}{}_medianselected_{}experiments_{}policies.tar.gz'.format(folder, key, nr_experiments, nr_policies)\n",
    "    try:\n",
    "        # why regenerate the data?\n",
    "        newResults[key] = load_results(new_fn)\n",
    "        print(key, newResults[key][0].shape)\n",
    "\n",
    "    except IOError:\n",
    "        newExperiments = experiments[logical_index]\n",
    "        newOutcomes = {}\n",
    "        for outcome in model.outcomes:\n",
    "            newOutcomes[outcome.name] = outcomes[outcome.name][logical_index]\n",
    "\n",
    "        newResults[key] = newExperiments, newOutcomes\n",
    "        save_results(newResults[key], new_fn)\n",
    "\n",
    "        print(key)\n",
    "        print(newResults[key][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_box = {'dps': {'b' : (0.100370, 0.239250), \n",
    "                    'delta': (0.930044, 0.959158),\n",
    "                    'q': (2.001502, 4.145256), \n",
    "                    'c1': (-0.104005, 1.731693)}, \n",
    "            'plannedadaptive': {'b' : (0.100637, 0.402237), \n",
    "                               'delta': (0.930046,0.944981)},\n",
    "            'intertemporal': {'b' : (0.100240, 0.261456), \n",
    "                              'delta': (0.930061,0.959012), \n",
    "                              'q' : (2.001704, 4.207757),\n",
    "                              'l1' : (0.006307, 0.088614), \n",
    "                              'l11' : (0.001967, 0.088614),\n",
    "                              'l12' : (0.000645, 0.088072),\n",
    "                              'l13' : (0.008911, 0.091266)}\n",
    "           }\n",
    "\n",
    "primIndex = {}\n",
    "primResults = {}\n",
    "for modelkey, model in models.items(): \n",
    "    print(modelkey)\n",
    "    experiments, outcomes = results[modelkey]\n",
    "    \n",
    "    prim_indices = []\n",
    "    for key, value in prim_box[modelkey].items():  \n",
    "        a_ = experiments[key] >= value[0]\n",
    "        b_ = experiments[key] <= value[1]\n",
    "        c = [np.array([a, b]).all() for a, b in zip(a_, b_)]\n",
    "        prim_indices.append(c)\n",
    "\n",
    "    prim_indices = np.swapaxes(prim_indices, 0, 1)\n",
    "    prim_logical_index = np.array([index.all() for index in prim_indices])\n",
    "    \n",
    "    newExperiments = experiments[prim_logical_index]\n",
    "    newOutcomes = {}\n",
    "    for outcome in model.outcomes:\n",
    "        newOutcomes[outcome.name] = outcomes[outcome.name][logical_index]\n",
    "        \n",
    "    print(newExperiments.shape)\n",
    "    primResults[modelkey] = newExperiments, newOutcomes\n",
    "    primIndex[modelkey] = prim_logical_index\n",
    "\n",
    "    new_fn = '{}{}_primselected_{}experiments_{}policies.tar.gz'.format(folder, modelkey, nr_experiments, nr_policies)\n",
    "    save_results(primResults[modelkey], new_fn)\n",
    "    \n",
    "# Display value ranges of the identified vulnerable scenarios \n",
    "selectedValueRanges(newResults, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charting\n",
    "\n",
    "Done on a per model basis, with settings configured in the first box of this notebook. \n",
    "\n",
    "This requires the maximally diverse set of alternatives to be found, which is done in `MaxDiverseSeelct.py` in a separate effort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='intertemporal'\n",
    "\n",
    "experiments, outcomes = results[key]\n",
    "oois = sorted(outcomes.keys())\n",
    "\n",
    "imageFolder = 'images/scenarioselect/policy10/'+key+'/'\n",
    "if not os.path.exists(imageFolder):\n",
    "    os.makedirs(imageFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_column = logicalIndex[key].astype(int)\n",
    "\n",
    "count = 0\n",
    "for index, i in enumerate(sel_column):            \n",
    "    if index in randomSelected:\n",
    "        sel_column[index] = 3\n",
    "        \n",
    "    if i:\n",
    "        if count in maxDiverse[key]:\n",
    "            sel_column[index] = 4\n",
    "        count +=1\n",
    "\n",
    "data = copy.copy(outcomes)\n",
    "data['selected'] = sel_column\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "set(sel_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper = pd.DataFrame(experiments)\n",
    "df = pd.concat([exper, data], axis=1, join_axes=[data.index])\n",
    "\n",
    "print('Maximally diverse scenarios')\n",
    "diverse = df[df['selected']==4][['b','q','delta','mean', 'stdev']]\n",
    "ICD.display(diverse)\n",
    "diverse.to_csv(imageFolder + key + '_maxdiverse.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "sns.axes_style('white')\n",
    "colors = ['#DCDCDC', '#A9A9A9', '#696969', fullColors[key]['multi'][3], fullColors[key]['multi'][0]]\n",
    "\n",
    "titles = ['any', 'policy relevant', 'prim', 'random_selected', 'diversity_selected']\n",
    "for idx in range(5): \n",
    "    data.loc[data['selected']==idx, 'hue'] = titles[idx]\n",
    "    \n",
    "g = sns.pairplot(data, hue='hue', size=2, markers = ['.', '.','.', 'o', 'o'],\n",
    "             palette=colors, hue_order=titles, vars=oois)\n",
    "\n",
    "tag_indices = {0: 'inertia', 1: 'max_P', 2: 'reliability', 3: 'utility'}\n",
    "\n",
    "save_fig(g, imageFolder, key + '_pairplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the selected four scenarios\n",
    "\n",
    "Use parallel plots to explore the selected scenarios in relation to the entire set of experiment results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)    \n",
    "sns.set_style('white', {'axes.edgecolor':'lightgrey'})\n",
    "\n",
    "ref = {'b':.42,'delta':.98,'mean':0.02,'q':2,'stdev':0.0017}\n",
    "\n",
    "def parallel_plot_selected_annotated(data, scenarios, title, t=1):\n",
    "    baseRef = {'b':.42,'delta':.98,'mean':0.02,'q':2,'stdev':0.0017}\n",
    "    baseRef = pd.DataFrame([baseRef])\n",
    "    \n",
    "    tags = ['1','2','3','4']\n",
    "    scenarioTags = {'Ref': 'Ref'}\n",
    "    for idx, val in enumerate(scenarios):\n",
    "        scenarioTags[val] = tags[idx]\n",
    "    \n",
    "    experiments, outcomes = data\n",
    "    labels = ['b', 'q', 'delta', 'mean', 'stdev']\n",
    "    df_experiments = pd.DataFrame(experiments)\n",
    "    df_experiments = df_experiments[['b', 'q', 'delta', 'mean', 'stdev']]\n",
    "    \n",
    "#     df = pd.concat([df_experiments, df_outcomes], axis=1, join_axes=[df_outcomes.index])\n",
    "    df = df_experiments\n",
    "    df = pd.concat([df, baseRef]).reset_index(drop=True)\n",
    "\n",
    "    minima = np.min(df, axis=0)\n",
    "    maxima = np.max(df, axis=0)\n",
    "\n",
    "    for uncert in models[key].uncertainties: \n",
    "        minima[uncert.name] = uncert.lower_bound\n",
    "        maxima[uncert.name] = uncert.upper_bound\n",
    "    \n",
    "    axes = setup_parallel_plot(labels, maxima, minima, [], 0)\n",
    "    normed_data = normalize(df, minima, maxima)\n",
    "    normed_ref = normalize(baseRef, minima, maxima)\n",
    "    #normed_data = normed_data.sort_index(axis=1) #re-ordering the columns of the df to align the grid with the df\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8, 5)\n",
    "    \n",
    "    if normed_data.shape[0] > 500: \n",
    "        viewGray = normed_data.sample(500)\n",
    "    else: \n",
    "        viewGray = normed_data\n",
    "        \n",
    "    colors = fullColors[key]['multi']\n",
    "    leg_labels = []\n",
    "    some_identifiers = []\n",
    "    for j in range(len(labels)-1):\n",
    "        ax = axes[j]\n",
    "        y = viewGray.ix[:, j:j+2]\n",
    "        x = np.tile([j+1,j+2], (y.shape[0], 1))\n",
    "        ax.plot(x.T, y.T, color='grey', linewidth=0.3)\n",
    "        \n",
    "        y_selected = normed_ref.ix[0, j:j+2]\n",
    "        ax.plot(x.T, y_selected.T, color=colors[0], lw=3)\n",
    "        if j == 3:\n",
    "            leg_labels.append(\"Scenario {}\".format(scenarioTags['Ref']))\n",
    "            artist = plt.Rectangle((0,0), 1,1, edgecolor=colors[4], facecolor=colors[4])\n",
    "            some_identifiers.append(artist)\n",
    "        \n",
    "        for i, s in enumerate(scenarios):\n",
    "            y_selected = normed_data.ix[s, j:j+2]\n",
    "            ax.plot(x.T, y_selected.T, color=colors[i+1], lw=3)\n",
    "            if j == 0:\n",
    "                if s in scenarioTags: \n",
    "                    leg_labels.append(\"Scenario {}\".format(scenarioTags[s]))\n",
    "                else: \n",
    "                    leg_labels.append(\"Scenario {}\".format(s))\n",
    "                artist = plt.Rectangle((0,0), 1,1, edgecolor=colors[i], facecolor=colors[i])\n",
    "                some_identifiers.append(artist)\n",
    "                \n",
    "    plt.legend(some_identifiers, leg_labels, loc=2, bbox_to_anchor=(1.05, 0.9), borderaxespad=0., fontsize=13)\n",
    "    plt.suptitle(modelTitle[key].replace('\\n',' '))\n",
    "    \n",
    "    change_fontsize(fig, 12)\n",
    "    save_fig(fig, imageFolder, title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='intertemporal'\n",
    "parallel_plot_selected_annotated(newResults[key], maxDiverse[key], key + '_selected_maxdiverse_parallel')\n",
    "# parallel_plot_selected_annotated(results[key], randomSelected, key + '_selected_random_parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='plannedadaptive'\n",
    "parallel_plot_selected_annotated(newResults[key], maxDiverse[key], key + '_selected_maxdiverse_parallel')\n",
    "# parallel_plot_selected_annotated(results[key], randomSelected, key + '_selected_random_parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='dps'\n",
    "parallel_plot_selected_annotated(newResults[key], maxDiverse[key], key + '_selected_maxdiverse_parallel')\n",
    "# parallel_plot_selected_annotated(results[key], randomSelected, key + '_selected_random_parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
